{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yangxin666/STD-GAE/blob/scripts/STD_GAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spatio-Temporal Denoising Graph Autoencoder (STD-GAE) \n",
        "\n",
        "STD-GAE exploits temporal correlation, spatial coherence and value dependencies from domain knowledge to recover missing data. It is empowered by two modules. \n",
        "\n",
        "1.   To cope with sparse yet various scenarios of missing data, STD-GAE incorporates a domain-knowledge aware data augmentation module\n",
        "that creates plausible variations of missing data patterns. This gen-\n",
        "eralizes STD-GAE to robust imputation over different seasons and\n",
        "environment.\n",
        "2.   STD-GAE nontrivially integrates spatiotemporal\n",
        "graph convolution layers (to recover local missing data by observed\n",
        "“neighboring” PV plants) and denoising autoencoder (to recover\n",
        "corrupted data from augmented counterpart) to improve the accu-\n",
        "racy of imputation accuracy at PV fleet level. \n",
        "\n"
      ],
      "metadata": {
        "id": "10qCANVbEbPm"
      },
      "id": "10qCANVbEbPm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Set Up"
      ],
      "metadata": {
        "id": "hCQ5WkJFDv_I"
      },
      "id": "hCQ5WkJFDv_I"
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that this installation can take a while! Be patient!\n",
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.10.0+${CUDA}.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.10.0+${CUDA}.html\n",
        "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.10.0+${CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.10.0+${CUDA}.html\n",
        "!pip install torch-geometric\n",
        "!pip install torch-geometric-temporal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY52RnmowMFP",
        "outputId": "5493e06d-b895-4204-e148-898bbae4a11f"
      },
      "id": "aY52RnmowMFP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+.html\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.0.9.tar.gz (21 kB)\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl size=279639 sha256=8ea936fd0e071a29f7d2065c65eb9d103213d94ac9455416905a53761ee40ae8\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/57/a3/42ea193b77378ce634eb9454c9bc1e3163f3b482a35cdee4d1\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+.html\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.13.tar.gz (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl size=501789 sha256=a761beff830b62f301d1b0f87000aa7fc464ec82f71e050c81edcac995c4ddaa\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/01/be/6b2966e0ff20bb023ae35e5d17903e6e5b4df46dd5892f6be6\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.13\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+.html\n",
            "Collecting torch-cluster\n",
            "  Downloading torch_cluster-1.6.0.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: torch-cluster\n",
            "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-cluster: filename=torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl size=309643 sha256=a7ec78d9dcb73d762e879cf1782d3dd705075ba4dd76e21c67ac7eacc3f84154\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/c7/3e/258dd72b35d7a459264143ad5bfe97b9dc5eef90069ca2f13f\n",
            "Successfully built torch-cluster\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading torch_spline_conv-1.2.1.tar.gz (13 kB)\n",
            "Building wheels for collected packages: torch-spline-conv\n",
            "  Building wheel for torch-spline-conv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-spline-conv: filename=torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl size=133303 sha256=58cb03c9b7f3d0815ad65370d86ce1b9e8235261ec706a10dc0ca09f260e89cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/33/73/780370b7c7bdf2340c0a7b971e915643f14795b4caa7a9a31f\n",
            "Successfully built torch-spline-conv\n",
            "Installing collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.4.tar.gz (407 kB)\n",
            "\u001b[K     |████████████████████████████████| 407 kB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.8)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616603 sha256=73c397c281b8ce890ba8ce32edff13184d34f0852a4d961cecfa9b8e4cbb58d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/a6/a4/ca18c3051fcead866fe7b85700ee2240d883562a1bc70ce421\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.0.4\n",
            "Collecting torch-geometric-temporal\n",
            "  Downloading torch_geometric_temporal-0.52.0.tar.gz (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric-temporal) (4.4.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torch-geometric-temporal) (1.11.0+cu113)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from torch-geometric-temporal) (0.29.28)\n",
            "Requirement already satisfied: pandas<=1.3.5 in /usr/local/lib/python3.7/dist-packages (from torch-geometric-temporal) (1.3.5)\n",
            "Requirement already satisfied: torch_sparse in /usr/local/lib/python3.7/dist-packages (from torch-geometric-temporal) (0.6.13)\n",
            "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.7/dist-packages (from torch-geometric-temporal) (2.0.9)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.7/dist-packages (from torch-geometric-temporal) (2.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric-temporal) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric-temporal) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric-temporal) (4.64.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torch-geometric-temporal) (1.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric-temporal) (2.6.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<=1.3.5->torch-geometric-temporal) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<=1.3.5->torch-geometric-temporal) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torch-geometric-temporal) (4.2.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch_geometric->torch-geometric-temporal) (3.0.8)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch_geometric->torch-geometric-temporal) (1.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch_geometric->torch-geometric-temporal) (2.23.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch_geometric->torch-geometric-temporal) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch_geometric->torch-geometric-temporal) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (2021.10.8)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch_geometric->torch-geometric-temporal) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch_geometric->torch-geometric-temporal) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric-temporal\n",
            "  Building wheel for torch-geometric-temporal (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric-temporal: filename=torch_geometric_temporal-0.52.0-py3-none-any.whl size=86194 sha256=fc4a88ac8cea136c8d45ae9ca52d15562324b2a3ccba3656d8b8aa4a13c1bc9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/eb/f1/e5/dd02c6d1e5f00f907f5e4894c60c5a21b774db1ed7464d0c23\n",
            "Successfully built torch-geometric-temporal\n",
            "Installing collected packages: torch-geometric-temporal\n",
            "Successfully installed torch-geometric-temporal-0.52.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6864f00-17c3-4b8a-a066-808dbd256613",
      "metadata": {
        "id": "d6864f00-17c3-4b8a-a066-808dbd256613",
        "outputId": "02d4d2cb-eb57-41a0-a4d9-a352ef7f7865",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "#import geopy.distance # to compute distances between stations\n",
        "import glob\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "#from torch_geometric_temporal.nn import STConv\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import ChebConv\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generate Edge Weight Matrix "
      ],
      "metadata": {
        "id": "mYgyw7lt2FQN"
      },
      "id": "mYgyw7lt2FQN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We represent the spatiotemporal PV data as an undirected graph $G = (V, E, X_{t})$. \n",
        "\n",
        "1.   Each node in $V$ represents a PV inverter\n",
        "2.   Edges $E$ are assigned according to Edge Weight Matrix (if $W_{i,j}$ > 0, then there is edge between i and j)\n",
        "3.   $X_{t}$ denotes a node attribute tensor $\\in \\mathbb{R}^{T\\times n\\times d}$. Here T is the length of timeseries, $n$ is the number of nodes (which is 98 in our study), and $d$ is the number of input channel.\n",
        "\n",
        "Since the locations of PV inverters are fixed, the graph structure is static with time-invariant nodes and edges. \n",
        "However, $X_{t}$ is time-varying: each node i carries a  timeseries $x_{i} \\in \\mathbb{R}^{T\\times d}$ recording attributes \n",
        "such as temperature, wind speed, \n",
        "irradiance and power output."
      ],
      "metadata": {
        "id": "ENvs9ivC2KUD"
      },
      "id": "ENvs9ivC2KUD"
    },
    {
      "cell_type": "code",
      "source": [
        "from math import radians, cos, sin, asin, sqrt\n",
        "\n",
        "def haversine(lon1, lat1, lon2, lat2):\n",
        "    \"\"\"\n",
        "    Calculate the great circle distance in kilometers between two points \n",
        "    on the earth (specified in decimal degrees)\n",
        "    \"\"\"\n",
        "    # convert decimal degrees to radians \n",
        "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
        "\n",
        "    # haversine formula \n",
        "    dlon = lon2 - lon1 \n",
        "    dlat = lat2 - lat1 \n",
        "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
        "    c = 2 * asin(sqrt(a)) \n",
        "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles. Determines return value units.\n",
        "    return c * r"
      ],
      "metadata": {
        "id": "XuqTiBY_2IRh"
      },
      "id": "XuqTiBY_2IRh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# please change the path according to your setting\n",
        "location = pd.read_csv('gdrive/My Drive/STGCN/location.csv',index_col=0)\n",
        "distance = np.zeros(shape=(98,98))\n",
        "dist = []\n",
        "for i in range(98):\n",
        "    for j in range(98):\n",
        "        d = haversine(location.iloc[i][2], location.iloc[i][1], location.iloc[j][2], location.iloc[j][1])\n",
        "        distance[i][j] = d\n",
        "        dist.append(d)\n",
        "\n",
        "dist_std = np.std(dist)\n",
        "distance = pd.DataFrame(distance)\n",
        "distance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "qYGJu5AN2IXB",
        "outputId": "616e6209-a5de-4ca3-f2e4-914b58318600"
      },
      "id": "qYGJu5AN2IXB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0           1           2           3           4           5   \\\n",
              "0     0.000000   41.877922  155.867227    0.000000    0.000000    0.000000   \n",
              "1    41.877922    0.000000  197.410750   41.877922   41.877922   41.877922   \n",
              "2   155.867227  197.410750    0.000000  155.867227  155.867227  155.867227   \n",
              "3     0.000000   41.877922  155.867227    0.000000    0.000000    0.000000   \n",
              "4     0.000000   41.877922  155.867227    0.000000    0.000000    0.000000   \n",
              "..         ...         ...         ...         ...         ...         ...   \n",
              "93    5.266638   36.923574  161.049981    5.266638    5.266638    5.266638   \n",
              "94  155.867227  197.410750    0.000000  155.867227  155.867227  155.867227   \n",
              "95   41.877922    0.000000  197.410750   41.877922   41.877922   41.877922   \n",
              "96   19.225334   56.183554  142.144836   19.225334   19.225334   19.225334   \n",
              "97   19.225334   56.183554  142.144836   19.225334   19.225334   19.225334   \n",
              "\n",
              "            6           7           8           9   ...          88  \\\n",
              "0     0.000000   19.225334   19.225334    5.266638  ...  155.867227   \n",
              "1    41.877922   56.183554   56.183554   36.923574  ...  197.410750   \n",
              "2   155.867227  142.144836  142.144836  161.049981  ...    0.000000   \n",
              "3     0.000000   19.225334   19.225334    5.266638  ...  155.867227   \n",
              "4     0.000000   19.225334   19.225334    5.266638  ...  155.867227   \n",
              "..         ...         ...         ...         ...  ...         ...   \n",
              "93    5.266638   23.874407   23.874407    0.000000  ...  161.049981   \n",
              "94  155.867227  142.144836  142.144836  161.049981  ...    0.000000   \n",
              "95   41.877922   56.183554   56.183554   36.923574  ...  197.410750   \n",
              "96   19.225334    0.000000    0.000000   23.874407  ...  142.144836   \n",
              "97   19.225334    0.000000    0.000000   23.874407  ...  142.144836   \n",
              "\n",
              "             89           90          91          92          93          94  \\\n",
              "0   1053.699461  1049.551406  408.413317  408.413317    5.266638  155.867227   \n",
              "1   1042.315749  1038.231327  406.551974  406.551974   36.923574  197.410750   \n",
              "2   1128.415790  1124.103674  470.203780  470.203780  161.049981    0.000000   \n",
              "3   1053.699461  1049.551406  408.413317  408.413317    5.266638  155.867227   \n",
              "4   1053.699461  1049.551406  408.413317  408.413317    5.266638  155.867227   \n",
              "..          ...          ...         ...         ...         ...         ...   \n",
              "93  1050.654946  1046.513358  406.295259  406.295259    0.000000  161.049981   \n",
              "94  1128.415790  1124.103674  470.203780  470.203780  161.049981    0.000000   \n",
              "95  1042.315749  1038.231327  406.551974  406.551974   36.923574  197.410750   \n",
              "96  1071.415648  1067.256618  424.409207  424.409207   23.874407  142.144836   \n",
              "97  1071.415648  1067.256618  424.409207  424.409207   23.874407  142.144836   \n",
              "\n",
              "            95          96          97  \n",
              "0    41.877922   19.225334   19.225334  \n",
              "1     0.000000   56.183554   56.183554  \n",
              "2   197.410750  142.144836  142.144836  \n",
              "3    41.877922   19.225334   19.225334  \n",
              "4    41.877922   19.225334   19.225334  \n",
              "..         ...         ...         ...  \n",
              "93   36.923574   23.874407   23.874407  \n",
              "94  197.410750  142.144836  142.144836  \n",
              "95    0.000000   56.183554   56.183554  \n",
              "96   56.183554    0.000000    0.000000  \n",
              "97   56.183554    0.000000    0.000000  \n",
              "\n",
              "[98 rows x 98 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fbd0e66e-5729-456d-9f9c-61288422a812\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>41.877922</td>\n",
              "      <td>155.867227</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>19.225334</td>\n",
              "      <td>19.225334</td>\n",
              "      <td>5.266638</td>\n",
              "      <td>...</td>\n",
              "      <td>155.867227</td>\n",
              "      <td>1053.699461</td>\n",
              "      <td>1049.551406</td>\n",
              "      <td>408.413317</td>\n",
              "      <td>408.413317</td>\n",
              "      <td>5.266638</td>\n",
              "      <td>155.867227</td>\n",
              "      <td>41.877922</td>\n",
              "      <td>19.225334</td>\n",
              "      <td>19.225334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>41.877922</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>197.410750</td>\n",
              "      <td>41.877922</td>\n",
              "      <td>41.877922</td>\n",
              "      <td>41.877922</td>\n",
              "      <td>41.877922</td>\n",
              "      <td>56.183554</td>\n",
              "      <td>56.183554</td>\n",
              "      <td>36.923574</td>\n",
              "      <td>...</td>\n",
              "      <td>197.410750</td>\n",
              "      <td>1042.315749</td>\n",
              "      <td>1038.231327</td>\n",
              "      <td>406.551974</td>\n",
              "      <td>406.551974</td>\n",
              "      <td>36.923574</td>\n",
              "      <td>197.410750</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>56.183554</td>\n",
              "      <td>56.183554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>155.867227</td>\n",
              "      <td>197.410750</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>155.867227</td>\n",
              "      <td>155.867227</td>\n",
              "      <td>155.867227</td>\n",
              "      <td>155.867227</td>\n",
              "      <td>142.144836</td>\n",
              "      <td>142.144836</td>\n",
              "      <td>161.049981</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1128.415790</td>\n",
              "      <td>1124.103674</td>\n",
              "      <td>470.203780</td>\n",
              "      <td>470.203780</td>\n",
              "      <td>161.049981</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>197.410750</td>\n",
              "      <td>142.144836</td>\n",
              "      <td>142.144836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>41.877922</td>\n",
              "      <td>155.867227</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>19.225334</td>\n",
              "      <td>19.225334</td>\n",
              "      <td>5.266638</td>\n",
              "      <td>...</td>\n",
              "      <td>155.867227</td>\n",
              "      <td>1053.699461</td>\n",
              "      <td>1049.551406</td>\n",
              "      <td>408.413317</td>\n",
              "      <td>408.413317</td>\n",
              "      <td>5.266638</td>\n",
              "      <td>155.867227</td>\n",
              "      <td>41.877922</td>\n",
              "      <td>19.225334</td>\n",
              "      <td>19.225334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>41.877922</td>\n",
              "      <td>155.867227</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>19.225334</td>\n",
              "      <td>19.225334</td>\n",
              "      <td>5.266638</td>\n",
              "      <td>...</td>\n",
              "      <td>155.867227</td>\n",
              "      <td>1053.699461</td>\n",
              "      <td>1049.551406</td>\n",
              "      <td>408.413317</td>\n",
              "      <td>408.413317</td>\n",
              "      <td>5.266638</td>\n",
              "      <td>155.867227</td>\n",
              "      <td>41.877922</td>\n",
              "      <td>19.225334</td>\n",
              "      <td>19.225334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>5.266638</td>\n",
              "      <td>36.923574</td>\n",
              "      <td>161.049981</td>\n",
              "      <td>5.266638</td>\n",
              "      <td>5.266638</td>\n",
              "      <td>5.266638</td>\n",
              "      <td>5.266638</td>\n",
              "      <td>23.874407</td>\n",
              "      <td>23.874407</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>161.049981</td>\n",
              "      <td>1050.654946</td>\n",
              "      <td>1046.513358</td>\n",
              "      <td>406.295259</td>\n",
              "      <td>406.295259</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>161.049981</td>\n",
              "      <td>36.923574</td>\n",
              "      <td>23.874407</td>\n",
              "      <td>23.874407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>155.867227</td>\n",
              "      <td>197.410750</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>155.867227</td>\n",
              "      <td>155.867227</td>\n",
              "      <td>155.867227</td>\n",
              "      <td>155.867227</td>\n",
              "      <td>142.144836</td>\n",
              "      <td>142.144836</td>\n",
              "      <td>161.049981</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1128.415790</td>\n",
              "      <td>1124.103674</td>\n",
              "      <td>470.203780</td>\n",
              "      <td>470.203780</td>\n",
              "      <td>161.049981</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>197.410750</td>\n",
              "      <td>142.144836</td>\n",
              "      <td>142.144836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>41.877922</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>197.410750</td>\n",
              "      <td>41.877922</td>\n",
              "      <td>41.877922</td>\n",
              "      <td>41.877922</td>\n",
              "      <td>41.877922</td>\n",
              "      <td>56.183554</td>\n",
              "      <td>56.183554</td>\n",
              "      <td>36.923574</td>\n",
              "      <td>...</td>\n",
              "      <td>197.410750</td>\n",
              "      <td>1042.315749</td>\n",
              "      <td>1038.231327</td>\n",
              "      <td>406.551974</td>\n",
              "      <td>406.551974</td>\n",
              "      <td>36.923574</td>\n",
              "      <td>197.410750</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>56.183554</td>\n",
              "      <td>56.183554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>19.225334</td>\n",
              "      <td>56.183554</td>\n",
              "      <td>142.144836</td>\n",
              "      <td>19.225334</td>\n",
              "      <td>19.225334</td>\n",
              "      <td>19.225334</td>\n",
              "      <td>19.225334</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>23.874407</td>\n",
              "      <td>...</td>\n",
              "      <td>142.144836</td>\n",
              "      <td>1071.415648</td>\n",
              "      <td>1067.256618</td>\n",
              "      <td>424.409207</td>\n",
              "      <td>424.409207</td>\n",
              "      <td>23.874407</td>\n",
              "      <td>142.144836</td>\n",
              "      <td>56.183554</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>19.225334</td>\n",
              "      <td>56.183554</td>\n",
              "      <td>142.144836</td>\n",
              "      <td>19.225334</td>\n",
              "      <td>19.225334</td>\n",
              "      <td>19.225334</td>\n",
              "      <td>19.225334</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>23.874407</td>\n",
              "      <td>...</td>\n",
              "      <td>142.144836</td>\n",
              "      <td>1071.415648</td>\n",
              "      <td>1067.256618</td>\n",
              "      <td>424.409207</td>\n",
              "      <td>424.409207</td>\n",
              "      <td>23.874407</td>\n",
              "      <td>142.144836</td>\n",
              "      <td>56.183554</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>98 rows × 98 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fbd0e66e-5729-456d-9f9c-61288422a812')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fbd0e66e-5729-456d-9f9c-61288422a812 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fbd0e66e-5729-456d-9f9c-61288422a812');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next step, we compute $w_{ij}$ for each pair of nodes $(i, j)$ in the graph as presented in Yu et al. (2018):\n",
        "\n",
        "$W_{i,j} = \\begin{cases} \\exp{(-\\frac{d_{ij}^2}{\\sigma^2})}, i\\neq j \\text{ and } \\exp{(-\\frac{d_{ij}^2}{\\sigma^2})} \\leq \\epsilon \\\\ \n",
        "0 \\text{ otherwise }\n",
        "\\end{cases}$\n",
        "\n",
        "In this case, $d_{ij}$ for each pair of nodes $(i, j)$ is the distance between stations that we have computed above. $\\sigma$ is the standard deviation of the distances."
      ],
      "metadata": {
        "id": "gI2ZfOe13ZS_"
      },
      "id": "gI2ZfOe13ZS_"
    },
    {
      "cell_type": "code",
      "source": [
        "# epsilon = 0, 0.25, 0.5, 0.75, 1\n",
        "epsilon = 1\n",
        "sigma = dist_std\n",
        "W = np.zeros(shape=(98,98))\n",
        "\n",
        "for i in range(98):\n",
        "    for j in range(98):\n",
        "        if i == j: \n",
        "            W[i][j] = 0\n",
        "        else:\n",
        "            # Compute distance between stations\n",
        "            d_ij = distance.loc[i][j]\n",
        "            \n",
        "            # Compute weight w_ij\n",
        "            w_ij = np.exp(-d_ij**2 / sigma**2)\n",
        "            \n",
        "            if w_ij >= epsilon:\n",
        "                W[i, j] = w_ij\n",
        "\n",
        "W = pd.DataFrame(W)\n",
        "# please change the path according to your setting\n",
        "W.to_csv('gdrive/My Drive/STGCN/W_98.csv',index=False)"
      ],
      "metadata": {
        "id": "JEC0_3PE2IZ4"
      },
      "id": "JEC0_3PE2IZ4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Construction of STD-GAE \n",
        "\n",
        "\n",
        "*   Construct temporal & spatial layers -> ST Blocks (encoder & decoder) -> Graph Denoising Autoencoders \n",
        "*   Define Parameters\n",
        "*   Some utility functions\n",
        "\n",
        "\n",
        "Construction of STD-GAE is the foundation for later codes."
      ],
      "metadata": {
        "id": "NdGpxGEInQMM"
      },
      "id": "NdGpxGEInQMM"
    },
    {
      "cell_type": "markdown",
      "id": "210f1baf-a9e2-4f21-a62e-cf6e44cffcc6",
      "metadata": {
        "id": "210f1baf-a9e2-4f21-a62e-cf6e44cffcc6"
      },
      "source": [
        "Temporal Convolutional (TConv) Layers and Deconvolutional (DeConv) Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9668e94c-7e80-4961-9b3f-e9cb1f6dd6ff",
      "metadata": {
        "id": "9668e94c-7e80-4961-9b3f-e9cb1f6dd6ff"
      },
      "outputs": [],
      "source": [
        "class TemporalConv(nn.Module):\n",
        "\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        in_channels (int): Number of input features.\n",
        "        out_channels (int): Number of output features.\n",
        "        kernel_size (int): Convolutional kernel size.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels: int, out_channels: int, kernel_size, stride: int, padding: int):\n",
        "        super(TemporalConv, self).__init__()\n",
        "        self.conv_1 = nn.Conv2d(in_channels, out_channels, (1, kernel_size), (1, stride), (0,padding))\n",
        "        self.conv_2 = nn.Conv2d(in_channels, out_channels, (1, kernel_size), (1, stride), (0,padding))\n",
        "        self.conv_3 = nn.Conv2d(in_channels, out_channels, (1, kernel_size), (1, stride), (0,padding))\n",
        "\n",
        "    def forward(self, X: torch.FloatTensor) -> torch.FloatTensor:\n",
        "        \"\"\"Forward pass through temporal convolution block.\n",
        "\n",
        "        Arg types:\n",
        "            * **X** (torch.FloatTensor) -  Input data of shape\n",
        "                (batch_size, input_time_steps, num_nodes, in_channels).\n",
        "\n",
        "        Return types:\n",
        "            * **H** (torch.FloatTensor) - Output data of shape\n",
        "                (batch_size, in_channels, num_nodes, input_time_steps).\n",
        "        \"\"\"\n",
        "        X = X.permute(0, 3, 2, 1)\n",
        "        P = self.conv_1(X)\n",
        "        Q = torch.sigmoid(self.conv_2(X))\n",
        "        PQ = P * Q\n",
        "        H = F.relu(PQ + self.conv_3(X))\n",
        "        H = H.permute(0, 3, 2, 1)\n",
        "        return H\n",
        "\n",
        "class TemporalDeConv1(nn.Module):\n",
        "\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        in_channels (int): Number of input features.\n",
        "        out_channels (int): Number of output features.\n",
        "        kernel_size (int): Convolutional kernel size.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels: int, out_channels: int, kernel_size, stride: int, padding: int):\n",
        "        super(TemporalDeConv1, self).__init__()\n",
        "        self.conv_1 = nn.ConvTranspose2d(in_channels, out_channels, (1, kernel_size), (1, stride), (0,padding))\n",
        "        self.conv_2 = nn.ConvTranspose2d(in_channels, out_channels, (1, kernel_size),(1, stride), (0,padding))\n",
        "        self.conv_3 = nn.ConvTranspose2d(in_channels, out_channels, (1, kernel_size),(1, stride), (0,padding))\n",
        "\n",
        "    def forward(self, X: torch.FloatTensor) -> torch.FloatTensor:\n",
        "        \"\"\"Forward pass through temporal convolution block.\n",
        "\n",
        "        Arg types:\n",
        "            * **X** (torch.FloatTensor) -  Input data of shape\n",
        "                (batch_size, input_time_steps, num_nodes, in_channels).\n",
        "\n",
        "        Return types:\n",
        "            * **H** (torch.FloatTensor) - Output data of shape\n",
        "                (batch_size, in_channels, num_nodes, input_time_steps).\n",
        "        \"\"\"\n",
        "        X = X.permute(0, 3, 2, 1)\n",
        "        P = self.conv_1(X)\n",
        "        Q = torch.sigmoid(self.conv_2(X))\n",
        "        PQ = P * Q\n",
        "        H = F.relu(PQ + self.conv_3(X))\n",
        "        H = H.permute(0, 3, 2, 1)\n",
        "        return H\n",
        "\n",
        "class TemporalDeConv2(nn.Module):\n",
        "\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        in_channels (int): Number of input features.\n",
        "        out_channels (int): Number of output features.\n",
        "        kernel_size (int): Convolutional kernel size.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels: int, out_channels: int, kernel_size, stride: int):\n",
        "        super(TemporalDeConv2, self).__init__()\n",
        "        self.conv_1 = nn.ConvTranspose2d(in_channels, out_channels, (1, kernel_size),(1, stride))\n",
        "        self.conv_2 = nn.ConvTranspose2d(in_channels, out_channels, (1, kernel_size),(1, stride))\n",
        "        self.conv_3 = nn.ConvTranspose2d(in_channels, out_channels, (1, kernel_size),(1, stride))\n",
        "\n",
        "    def forward(self, X: torch.FloatTensor) -> torch.FloatTensor:\n",
        "        \"\"\"Forward pass through temporal convolution block.\n",
        "\n",
        "        Arg types:\n",
        "            * **X** (torch.FloatTensor) -  Input data of shape\n",
        "                (batch_size, input_time_steps, num_nodes, in_channels).\n",
        "\n",
        "        Return types:\n",
        "            * **H** (torch.FloatTensor) - Output data of shape\n",
        "                (batch_size, in_channels, num_nodes, input_time_steps).\n",
        "        \"\"\"\n",
        "        X = X.permute(0, 3, 2, 1)\n",
        "        P = self.conv_1(X)\n",
        "        Q = torch.sigmoid(self.conv_2(X))\n",
        "        PQ = P * Q\n",
        "        H = F.relu(PQ + self.conv_3(X))\n",
        "        H = H.permute(0, 3, 2, 1)\n",
        "        return H\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2c334b5-77e4-48fa-80eb-1789c838b76d",
      "metadata": {
        "id": "c2c334b5-77e4-48fa-80eb-1789c838b76d"
      },
      "source": [
        "Encoder: a Spaio-temporal Block (Temporal Conv + Spatial Conv + Temporal Conv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ba35dfd-375a-4735-be9d-39427fabf17f",
      "metadata": {
        "id": "8ba35dfd-375a-4735-be9d-39427fabf17f"
      },
      "outputs": [],
      "source": [
        "class STConvEncoder(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_nodes: int,\n",
        "        in_channels: int,\n",
        "        hidden_channels: int,\n",
        "        out_channels: int,\n",
        "        kernel_size: int,\n",
        "        stride: int,\n",
        "        padding: int,\n",
        "        K: int,\n",
        "        normalization: str = \"sym\",\n",
        "        bias: bool = True,\n",
        "    ):\n",
        "        super(STConvEncoder, self).__init__()\n",
        "        self.num_nodes = num_nodes\n",
        "        self.in_channels = in_channels\n",
        "        self.hidden_channels = hidden_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.K = K\n",
        "        self.normalization = normalization\n",
        "        self.bias = bias\n",
        "\n",
        "        self._temporal_conv1 = TemporalConv(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=hidden_channels,\n",
        "            kernel_size=kernel_size, stride = stride, padding = padding,\n",
        "        )\n",
        "\n",
        "        self._graph_conv = ChebConv(\n",
        "            in_channels=hidden_channels,\n",
        "            out_channels=hidden_channels,\n",
        "            K=K,\n",
        "            normalization=normalization,\n",
        "            bias=bias,\n",
        "        )\n",
        "\n",
        "        self._temporal_conv2 = TemporalConv(\n",
        "            in_channels=hidden_channels,\n",
        "            out_channels=out_channels,\n",
        "            kernel_size=kernel_size, stride = stride, padding = padding,\n",
        "        )\n",
        "\n",
        "        self._batch_norm = nn.BatchNorm2d(num_nodes)\n",
        "\n",
        "    def forward(self, X: torch.FloatTensor, edge_index: torch.LongTensor, edge_weight: torch.FloatTensor = None,) -> torch.FloatTensor:\n",
        "\n",
        "        r\"\"\"Forward pass. If edge weights are not present the forward pass\n",
        "        defaults to an unweighted graph.\n",
        "\n",
        "        Arg types:\n",
        "            * **X** (PyTorch FloatTensor) - Sequence of node features of shape (Batch size X Input time steps X Num nodes X In channels).\n",
        "            * **edge_index** (PyTorch LongTensor) - Graph edge indices.\n",
        "            * **edge_weight** (PyTorch LongTensor, optional)- Edge weight vector.\n",
        "\n",
        "        Return types:\n",
        "            * **T** (PyTorch FloatTensor) - Sequence of node features.\n",
        "        \"\"\"\n",
        "        #print(X.shape)\n",
        "        T_0 = self._temporal_conv1(X)\n",
        "        #print(T_0.shape)\n",
        "        T = torch.zeros_like(T_0).to(T_0.device)\n",
        "        for b in range(T_0.size(0)):\n",
        "            for t in range(T_0.size(1)):\n",
        "                T[b][t] = self._graph_conv(T_0[b][t], edge_index, edge_weight)\n",
        "\n",
        "        T = F.relu(T)\n",
        "        #print(T.shape)\n",
        "        T = self._temporal_conv2(T)\n",
        "        #print(T.shape)\n",
        "        # T = T.permute(0, 2, 1, 3)\n",
        "        # #print(T.shape)\n",
        "        # T = self._batch_norm(T)\n",
        "        # T = T.permute(0, 2, 1, 3)\n",
        "        #print(T.shape)\n",
        "\n",
        "        return T"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoder: a Spaio-temporal Block (Temporal DeConv + Spatial Conv + Temporal DeConv)"
      ],
      "metadata": {
        "id": "fIWM0QSHxYGW"
      },
      "id": "fIWM0QSHxYGW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f6b79b0-4633-4b1f-8dfc-27457007e78d",
      "metadata": {
        "id": "0f6b79b0-4633-4b1f-8dfc-27457007e78d"
      },
      "outputs": [],
      "source": [
        "class STConvDecoder(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_nodes: int,\n",
        "        in_channels: int,\n",
        "        hidden_channels: int,\n",
        "        out_channels: int,\n",
        "        kernel_size: int,\n",
        "        kernel_size_de: int,\n",
        "        stride: int,\n",
        "        padding: int,\n",
        "        K: int,\n",
        "        normalization: str = \"sym\",\n",
        "        bias: bool = True,\n",
        "    ):\n",
        "        super(STConvDecoder, self).__init__()\n",
        "        self.num_nodes = num_nodes\n",
        "        self.in_channels = in_channels\n",
        "        self.hidden_channels = hidden_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.K = K\n",
        "        self.normalization = normalization\n",
        "        self.bias = bias\n",
        "\n",
        "        self._temporal_conv1 = TemporalDeConv1(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=hidden_channels,\n",
        "            kernel_size=kernel_size, stride = stride, padding = padding,\n",
        "        )\n",
        "\n",
        "        self._graph_conv = ChebConv(\n",
        "            in_channels=hidden_channels,\n",
        "            out_channels=hidden_channels,\n",
        "            K=K,\n",
        "            normalization=normalization,\n",
        "            bias=bias,\n",
        "        )\n",
        "\n",
        "        self._temporal_conv2 = TemporalDeConv2(\n",
        "            in_channels=hidden_channels,\n",
        "            out_channels=out_channels,\n",
        "            kernel_size=kernel_size_de, stride = stride,\n",
        "        )\n",
        "\n",
        "        self._batch_norm = nn.BatchNorm2d(num_nodes)\n",
        "\n",
        "    def forward(self, X: torch.FloatTensor, edge_index: torch.LongTensor, edge_weight: torch.FloatTensor = None,) -> torch.FloatTensor:\n",
        "\n",
        "        r\"\"\"Forward pass. If edge weights are not present the forward pass\n",
        "        defaults to an unweighted graph.\n",
        "\n",
        "        Arg types:\n",
        "            * **X** (PyTorch FloatTensor) - Sequence of node features of shape (Batch size X Input time steps X Num nodes X In channels).\n",
        "            * **edge_index** (PyTorch LongTensor) - Graph edge indices.\n",
        "            * **edge_weight** (PyTorch LongTensor, optional)- Edge weight vector.\n",
        "\n",
        "        Return types:\n",
        "            * **T** (PyTorch FloatTensor) - Sequence of node features.\n",
        "        \"\"\"\n",
        "        T_0 = self._temporal_conv1(X)\n",
        "        T = torch.zeros_like(T_0).to(T_0.device)\n",
        "        for b in range(T_0.size(0)):\n",
        "            for t in range(T_0.size(1)):\n",
        "                T[b][t] = self._graph_conv(T_0[b][t], edge_index, edge_weight)\n",
        "\n",
        "        T = F.relu(T)\n",
        "        T = self._temporal_conv2(T)\n",
        "        # T = T.permute(0, 2, 1, 3)\n",
        "        # T = self._batch_norm(T)\n",
        "        # T = T.permute(0, 2, 1, 3)\n",
        "        return T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddbd233f-67bd-400a-81ac-8f9c80e29e52",
      "metadata": {
        "id": "ddbd233f-67bd-400a-81ac-8f9c80e29e52"
      },
      "source": [
        "Denoising Graph Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a43c31c-99b8-4edc-a6b2-ef29b20eef91",
      "metadata": {
        "id": "3a43c31c-99b8-4edc-a6b2-ef29b20eef91"
      },
      "outputs": [],
      "source": [
        "# a specified number of STConv blocks, followed by an output layer\n",
        "class STConvAE(torch.nn.Module):\n",
        "    def __init__(self, device, num_nodes, channel_size_list, num_layers, \n",
        "                 kernel_size, K, window_size, kernel_size_de, stride, padding,\\\n",
        "                 normalization = 'sym', bias = True):\n",
        "    # num_nodes = number of nodes in the input graph\n",
        "    # channel_size_list =  2d array representing feature dimensions throughout the model\n",
        "    # num_layers = number of STConv blocks\n",
        "    # kernel_size = length of the temporal kernel\n",
        "    # K = size of the chebyshev filter for the spatial convolution\n",
        "    # window_size = number of historical time steps to consider\n",
        "\n",
        "        super(STConvAE, self).__init__()\n",
        "        self.layers = nn.ModuleList([])\n",
        "        # add STConv blocks\n",
        "        for l in range(num_layers):\n",
        "            input_size, hidden_size, output_size = channel_size_list[l][0], channel_size_list[l][1], channel_size_list[l][2]\n",
        "            if l==0:\n",
        "                self.layers.append(STConvEncoder(num_nodes, input_size, hidden_size, output_size, kernel_size, stride, padding, K, normalization, bias))\n",
        "            if l==1:\n",
        "                self.layers.append(STConvDecoder(num_nodes, input_size, hidden_size, output_size, kernel_size, kernel_size_de, stride, padding, K, normalization, bias))\n",
        "        \n",
        "\n",
        "        # # add output layer\n",
        "        # self.layers.append(OutputLayer(channel_size_list[-1][-1], \\\n",
        "        #                                window_size - 2 * num_layers * (kernel_size - 1), \\\n",
        "        #                                num_nodes))\n",
        "        # CUDA if available\n",
        "        for layer in self.layers:\n",
        "            layer = layer.to(device)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight ):\n",
        "        #print(x.shape)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, edge_index, edge_weight)\n",
        "          #print(x.shape)\n",
        "        # out_layer = self.layers[-1]\n",
        "        # x = x.permute(0, 3, 1, 2)\n",
        "        # x = out_layer(x)\n",
        "        # print(x.shape)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71ffaeb1-4554-4646-ba19-84ffeffdef0a",
      "metadata": {
        "id": "71ffaeb1-4554-4646-ba19-84ffeffdef0a"
      },
      "source": [
        "Define Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee905283-33e3-496f-b1f0-317e3bd7e4ef",
      "metadata": {
        "id": "ee905283-33e3-496f-b1f0-317e3bd7e4ef"
      },
      "outputs": [],
      "source": [
        "# model parameters\n",
        "num_nodes = 98\n",
        "#channels = np.array([[1, 1, 1], [1, 1, 1]]) # sequence of channel sizes\n",
        "channels = np.array([[1, 4, 8], [8, 4, 1]])\n",
        "kernel_size = 4 # size of temporal kernel\n",
        "kernel_size_de = 2 # size of temporal deconv2\n",
        "stride = 2\n",
        "padding = 1\n",
        "K = 3 # chebyshev filter size\n",
        "\n",
        "# training parameters\n",
        "learning_rate = 0.001\n",
        "batch_size = 2\n",
        "num_epochs = 50 # note that we trained for 7 epochs using Google Cloud\n",
        "num_layers = 2 # number of STConv blocks\n",
        "n_his = 288 # window size\n",
        "train_prop = 2/3 # Our actual training set proportion was 0.7\n",
        "val_prop = 1/6 # Our actual training set proportion was 0.2\n",
        "test_prop = 1/6 # Our actual training set proportion was 0.1\n",
        "\n",
        "# model save path\n",
        "model_save_path = os.path.join('best_model_12hr_BM.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7c71a7d-988b-4f92-8ad9-ca54bc8a2409",
      "metadata": {
        "id": "c7c71a7d-988b-4f92-8ad9-ca54bc8a2409"
      },
      "source": [
        "Preparing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "618319d2-6ae2-448e-9dd4-b612eb239d18",
      "metadata": {
        "id": "618319d2-6ae2-448e-9dd4-b612eb239d18"
      },
      "outputs": [],
      "source": [
        "def data_transform(data, corrupted_data, window, device):\n",
        "    # data = slice of V matrix\n",
        "    # n_his = number of historical speed observations to consider\n",
        "    # n_pred = number of time steps in the future to predict\n",
        "\n",
        "    num_nodes = data.shape[1]\n",
        "    num_obs = int(len(data)/window)\n",
        "    x = np.zeros([num_obs, window, num_nodes, 1])\n",
        "    y = np.zeros([num_obs, window, num_nodes, 1])\n",
        "    \n",
        "    obs_idx = 0\n",
        "    for i in range(num_obs):\n",
        "        head = i*window\n",
        "        tail = (i+1)*window\n",
        "        y[obs_idx, :, :, :] = data[head: tail].reshape(n_his, num_nodes, 1)\n",
        "        x[obs_idx, :, :, :] = corrupted_data[head: tail].reshape(n_his, num_nodes, 1)\n",
        "        #x[obs_idx, :, :, :] = data[head: tail].reshape(n_his, num_nodes, 1)\n",
        "        obs_idx += 1\n",
        "\n",
        "    return torch.Tensor(x).to(device), torch.Tensor(y).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#STD-GAE Framework\n",
        "STD-GAE framework consists of the following four major components: data ingestion, data augmentation, data corruption, and STD-GAE."
      ],
      "metadata": {
        "id": "WfWIq-pD5gln"
      },
      "id": "WfWIq-pD5gln"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Ingestion"
      ],
      "metadata": {
        "id": "7K-ztQofpCUb"
      },
      "id": "7K-ztQofpCUb"
    },
    {
      "cell_type": "code",
      "source": [
        "# please change the path according to your setting\n",
        "W = pd.read_csv('gdrive/My Drive/STGCN/W_98.csv')\n",
        "D_O = pd.read_csv('gdrive/My Drive/STGCN/norm_power.csv')\n",
        "D_O"
      ],
      "metadata": {
        "id": "JRfhd9K4oRf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "ee8effcb-48f4-4c1e-8a42-fbacc34830bd"
      },
      "id": "JRfhd9K4oRf2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      0    1    2    3    4    5    6    7    8    9  ...  103670  103671  \\\n",
              "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
              "1   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
              "2   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
              "3   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
              "4   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
              "..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...     ...     ...   \n",
              "93  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
              "94  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
              "95  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
              "96  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
              "97  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0     0.0   \n",
              "\n",
              "    103672  103673  103674  103675  103676  103677  103678  103679  \n",
              "0      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
              "1      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
              "2      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
              "3      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
              "4      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
              "..     ...     ...     ...     ...     ...     ...     ...     ...  \n",
              "93     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
              "94     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
              "95     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
              "96     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
              "97     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
              "\n",
              "[98 rows x 103680 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94f53b21-0eeb-48fb-993e-de391a71ceaf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>103670</th>\n",
              "      <th>103671</th>\n",
              "      <th>103672</th>\n",
              "      <th>103673</th>\n",
              "      <th>103674</th>\n",
              "      <th>103675</th>\n",
              "      <th>103676</th>\n",
              "      <th>103677</th>\n",
              "      <th>103678</th>\n",
              "      <th>103679</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>98 rows × 103680 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94f53b21-0eeb-48fb-993e-de391a71ceaf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-94f53b21-0eeb-48fb-993e-de391a71ceaf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-94f53b21-0eeb-48fb-993e-de391a71ceaf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Augmentation"
      ],
      "metadata": {
        "id": "o03gr5pipODF"
      },
      "id": "o03gr5pipODF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bf38ec8-c553-48e2-81e4-4b5ff7a42df7",
      "metadata": {
        "id": "1bf38ec8-c553-48e2-81e4-4b5ff7a42df7",
        "outputId": "0400a649-65ee-408f-a63b-c2667274dd09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0    1    2    3    4    5    6    7    8    9   ...   88   89   90  \\\n",
              "0       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "1       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "2       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "3       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "4       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "103675  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "103676  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "103677  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "103678  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "103679  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "\n",
              "         91   92   93   94   95   96   97  \n",
              "0       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "1       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "2       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "3       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "4       0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "...     ...  ...  ...  ...  ...  ...  ...  \n",
              "103675  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "103676  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "103677  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "103678  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "103679  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
              "\n",
              "[103680 rows x 98 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e6faaec-43db-4f3d-9e8e-7247b9a9dfd4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103675</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103676</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103677</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103678</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103679</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>103680 rows × 98 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e6faaec-43db-4f3d-9e8e-7247b9a9dfd4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0e6faaec-43db-4f3d-9e8e-7247b9a9dfd4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0e6faaec-43db-4f3d-9e8e-7247b9a9dfd4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "D_O = D_O.T\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "D_O = pd.DataFrame(D_O)\n",
        "imputer.fit(D_O)\n",
        "D_A = imputer.transform(D_O)\n",
        "D_A = pd.DataFrame(D_A)\n",
        "D_A = D_A*100\n",
        "D_A.to_csv('gdrive/My Drive/STGCN/Data_Augmented.csv', index = False) \n",
        "D_A"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D_A.to_csv('gdrive/My Drive/STGCN/Data_Augmented.csv', index = False) "
      ],
      "metadata": {
        "id": "c06M6VZ384dh"
      },
      "id": "c06M6VZ384dh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Corruption"
      ],
      "metadata": {
        "id": "3tOPayWnp-Zf"
      },
      "id": "3tOPayWnp-Zf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We provide the choice of 12 different missing masks to corrupt, which includes:\n",
        "\n",
        "\n",
        "1.   Type I: Missing Completely at Random (MCAR): 10%, 20%, 30%, 40%, 50%, and 60%\n",
        "2.   Type II: Block Missing (BM): 2hrs, 4hrs, 6hrs, 8hrs, 10hrs, and 12hrs.\n",
        "\n",
        "The missing maks can be adjusted if the prior distribution of missing data is given.\n",
        "\n"
      ],
      "metadata": {
        "id": "PUkEbxPPqOw1"
      },
      "id": "PUkEbxPPqOw1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "MCAR Masks\n",
        "\n",
        "Please change the path according to your setting."
      ],
      "metadata": {
        "id": "o5ebdcJwqO7h"
      },
      "id": "o5ebdcJwqO7h"
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.FloatTensor(103680, 98).uniform_() > 0.1\n",
        "pd.DataFrame(mask.numpy()).to_csv('gdrive/My Drive/STGCN/10%MCAR.csv',index=False)"
      ],
      "metadata": {
        "id": "spw5QEXArXOa"
      },
      "id": "spw5QEXArXOa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.FloatTensor(103680, 98).uniform_() > 0.2\n",
        "pd.DataFrame(mask.numpy()).to_csv('gdrive/My Drive/STGCN/20%MCAR.csv',index=False)"
      ],
      "metadata": {
        "id": "YUb1wETurXSU"
      },
      "id": "YUb1wETurXSU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.FloatTensor(103680, 98).uniform_() > 0.3\n",
        "pd.DataFrame(mask.numpy()).to_csv('gdrive/My Drive/STGCN/30%MCAR.csv',index=False)"
      ],
      "metadata": {
        "id": "hptXD-6MrXU9"
      },
      "id": "hptXD-6MrXU9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.FloatTensor(103680, 98).uniform_() > 0.4\n",
        "pd.DataFrame(mask.numpy()).to_csv('gdrive/My Drive/STGCN/40%MCAR.csv',index=False)"
      ],
      "metadata": {
        "id": "RRyzvNv9reBg"
      },
      "id": "RRyzvNv9reBg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.FloatTensor(103680, 98).uniform_() > 0.5\n",
        "pd.DataFrame(mask.numpy()).to_csv('gdrive/My Drive/STGCN/50%MCAR.csv',index=False)"
      ],
      "metadata": {
        "id": "RPYYz1yMreFM"
      },
      "id": "RPYYz1yMreFM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.FloatTensor(103680, 98).uniform_() > 0.6\n",
        "pd.DataFrame(mask.numpy()).to_csv('gdrive/My Drive/STGCN/60%MCAR.csv',index=False)"
      ],
      "metadata": {
        "id": "_eTHVZzYreII"
      },
      "id": "_eTHVZzYreII",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BM Masks\n",
        "Please change the path according to your setting."
      ],
      "metadata": {
        "id": "X4RXqWl3rkBJ"
      },
      "id": "X4RXqWl3rkBJ"
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "length=24\n",
        "mask = torch.full((103680,98), True)\n",
        "for i in range(360):\n",
        "    for j in range(98):\n",
        "        number = random.randint(288*i+1,288*(i+1)-length-1)\n",
        "        mask[number:number+length, j] = False\n",
        "\n",
        "pd.DataFrame(mask.numpy()).to_csv('gdrive/My Drive/STGCN/2hr_BM.csv',index=False)"
      ],
      "metadata": {
        "id": "a4hixu8areK6"
      },
      "id": "a4hixu8areK6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "length=48\n",
        "mask = torch.full((103680,98), True)\n",
        "for i in range(360):\n",
        "    for j in range(98):\n",
        "        number = random.randint(288*i+1,288*(i+1)-length-1)\n",
        "        mask[number:number+length, j] = False\n",
        "\n",
        "pd.DataFrame(mask.numpy()).to_csv('gdrive/My Drive/STGCN/4hr_BM.csv',index=False)"
      ],
      "metadata": {
        "id": "uGoEiECsrnQL"
      },
      "id": "uGoEiECsrnQL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "length=72\n",
        "mask = torch.full((103680,98), True)\n",
        "for i in range(360):\n",
        "    for j in range(98):\n",
        "        number = random.randint(288*i+1,288*(i+1)-length-1)\n",
        "        mask[number:number+length, j] = False\n",
        "\n",
        "pd.DataFrame(mask.numpy()).to_csv('gdrive/My Drive/STGCN/6hr_BM.csv',index=False)"
      ],
      "metadata": {
        "id": "MeT_iUQbrnUQ"
      },
      "id": "MeT_iUQbrnUQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "length=96\n",
        "mask = torch.full((103680,98), True)\n",
        "for i in range(360):\n",
        "    for j in range(98):\n",
        "        number = random.randint(288*i+1,288*(i+1)-length-1)\n",
        "        mask[number:number+length, j] = False\n",
        "\n",
        "pd.DataFrame(mask.numpy()).to_csv('gdrive/My Drive/STGCN/8hr_BM.csv',index=False)"
      ],
      "metadata": {
        "id": "LJ2DVVtRrnXv"
      },
      "id": "LJ2DVVtRrnXv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "length=120\n",
        "mask = torch.full((103680,98), True)\n",
        "for i in range(360):\n",
        "    for j in range(98):\n",
        "        number = random.randint(288*i+1,288*(i+1)-length-1)\n",
        "        mask[number:number+length, j] = False\n",
        "\n",
        "pd.DataFrame(mask.numpy()).to_csv('gdrive/My Drive/STGCN/10hr_BM.csv',index=False)"
      ],
      "metadata": {
        "id": "809T0mMxrndr"
      },
      "id": "809T0mMxrndr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "length=144\n",
        "mask = torch.full((103680,98), True)\n",
        "for i in range(360):\n",
        "    for j in range(98):\n",
        "        number = random.randint(288*i+1,288*(i+1)-length-1)\n",
        "        mask[number:number+length, j] = False\n",
        "\n",
        "pd.DataFrame(mask.numpy()).to_csv('gdrive/My Drive/STGCN/12hr_BM.csv',index=False)"
      ],
      "metadata": {
        "id": "aIokuexcrnmq"
      },
      "id": "aIokuexcrnmq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a54b8116-cea3-4758-bf2b-4e46f58b474b",
      "metadata": {
        "id": "a54b8116-cea3-4758-bf2b-4e46f58b474b"
      },
      "outputs": [],
      "source": [
        "#Choose the mask you want to corrupt D_A: here we choose 12hrs BM\n",
        "mask = pd.read_csv('gdrive/My Drive/STGCN/12hr_BM.csv')\n",
        "mask = torch.tensor(mask.values)\n",
        "D_C = pd.read_csv('gdrive/My Drive/STGCN/Data_Augmented.csv')\n",
        "D_C[mask.numpy()==False] = -1\n",
        "D_A = pd.read_csv('gdrive/My Drive/STGCN/Data_Augmented.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#STD-GAE Training"
      ],
      "metadata": {
        "id": "EcZw-IpCtJad"
      },
      "id": "EcZw-IpCtJad"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing"
      ],
      "metadata": {
        "id": "ek7azuCztLk2"
      },
      "id": "ek7azuCztLk2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4e49ec5-c1fc-4a7e-be49-e8f25217c24c",
      "metadata": {
        "id": "f4e49ec5-c1fc-4a7e-be49-e8f25217c24c"
      },
      "outputs": [],
      "source": [
        "power_tensor = torch.tensor(D_A.values)\n",
        "length = D_A.shape[0]\n",
        "train_x = power_tensor[0:int(train_prop*length),:].to(torch.float32)\n",
        "validation_x = power_tensor[int(train_prop*length):int((train_prop+val_prop)*length)+1,:].to(torch.float32)\n",
        "test_x = power_tensor[int((train_prop+val_prop)*length)+1:length,:].to(torch.float32)\n",
        "\n",
        "power_corrupted_tensor = torch.tensor(D_C.values)\n",
        "length = D_C.shape[0]\n",
        "corrupted_train_x = power_corrupted_tensor[0:int(train_prop*length),:].to(torch.float32)\n",
        "corrupted_validation_x = power_corrupted_tensor[int(train_prop*length):int((train_prop+val_prop)*length)+1,:].to(torch.float32)\n",
        "corrupted_test_x = power_corrupted_tensor[int((train_prop+val_prop)*length)+1:length,:].to(torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd75a942-0388-4404-9318-aaea96da7b48",
      "metadata": {
        "id": "bd75a942-0388-4404-9318-aaea96da7b48"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() \\\n",
        "else torch.device(\"cpu\")\n",
        "\n",
        "x_train, y_train = data_transform(train_x.numpy(), corrupted_train_x.numpy(), n_his, device)\n",
        "x_val, y_val = data_transform(validation_x.numpy(), corrupted_validation_x.numpy(), n_his, device)\n",
        "x_test, y_test = data_transform(test_x.numpy(), corrupted_test_x.numpy(), n_his, device)\n",
        "\n",
        "# create torch data iterables for training\n",
        "train_data = torch.utils.data.TensorDataset(x_train, y_train)\n",
        "train_iter = torch.utils.data.DataLoader(train_data, batch_size, shuffle=True)\n",
        "val_data = torch.utils.data.TensorDataset(x_val, y_val)\n",
        "val_iter = torch.utils.data.DataLoader(val_data, batch_size)\n",
        "test_data = torch.utils.data.TensorDataset(x_test, y_test)\n",
        "test_iter = torch.utils.data.DataLoader(test_data, batch_size)\n",
        "\n",
        "# format graph for pyg layer inputs\n",
        "G = sp.coo_matrix(W)\n",
        "edge_index = torch.tensor(np.array([G.row, G.col]), dtype=torch.int64).to(device)\n",
        "edge_weight = torch.tensor(G.data).float().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9c78ceb-fd9f-4b0f-bd06-09ec43b67f04",
      "metadata": {
        "id": "c9c78ceb-fd9f-4b0f-bd06-09ec43b67f04"
      },
      "source": [
        "Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f59c4e1-c3d7-4b9a-ad72-8f56485c16c4",
      "metadata": {
        "id": "6f59c4e1-c3d7-4b9a-ad72-8f56485c16c4"
      },
      "outputs": [],
      "source": [
        "model = STConvAE(device, num_nodes, channels, num_layers, kernel_size, K, n_his, kernel_size_de, stride, padding, normalization = 'sym', bias = True).to(device)\n",
        "# define loss function\n",
        "loss = nn.MSELoss()\n",
        "# define optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = 0.02) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4380158a-750f-4644-aadc-405818b3a385",
      "metadata": {
        "id": "4380158a-750f-4644-aadc-405818b3a385",
        "outputId": "36fa8dee-9764-4614-aaf5-df7efb1fb66f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:50<00:00,  1.09it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:20<00:00,  1.44it/s]\n",
            "Epoch:   2%|▏         | 1/50 [02:11<1:47:19, 131.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 \t\t Training Loss: 464.1682365894318 \t\t Validation Loss: 806.0076487223307\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:48<00:00,  1.10it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:20<00:00,  1.50it/s]\n",
            "Epoch:   4%|▍         | 2/50 [04:20<1:44:00, 130.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 \t\t Training Loss: 382.2497326850891 \t\t Validation Loss: 736.9133895874023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:57<00:00,  1.02it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:20<00:00,  1.48it/s]\n",
            "Epoch:   6%|▌         | 3/50 [06:38<1:44:34, 133.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 \t\t Training Loss: 362.98468621571857 \t\t Validation Loss: 713.095302327474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:52<00:00,  1.07it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:19<00:00,  1.52it/s]\n",
            "Epoch:   8%|▊         | 4/50 [08:50<1:41:56, 132.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 \t\t Training Loss: 353.31300552686054 \t\t Validation Loss: 711.2932927449544\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:48<00:00,  1.11it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:19<00:00,  1.51it/s]\n",
            "Epoch:  10%|█         | 5/50 [10:58<1:38:27, 131.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 \t\t Training Loss: 347.3608175913493 \t\t Validation Loss: 690.6288345336914\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:47<00:00,  1.12it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:19<00:00,  1.51it/s]\n",
            "Epoch:  12%|█▏        | 6/50 [13:05<1:35:19, 129.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 \t\t Training Loss: 343.08521839777626 \t\t Validation Loss: 684.298166402181\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:59<00:00,  1.01it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:20<00:00,  1.50it/s]\n",
            "Epoch:  14%|█▍        | 7/50 [15:25<1:35:16, 132.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 \t\t Training Loss: 340.1606243133545 \t\t Validation Loss: 685.8173940022787\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:48<00:00,  1.10it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:20<00:00,  1.49it/s]\n",
            "Epoch:  16%|█▌        | 8/50 [17:33<1:32:09, 131.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 \t\t Training Loss: 337.65112489064535 \t\t Validation Loss: 673.4765324910481\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:50<00:00,  1.08it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:20<00:00,  1.50it/s]\n",
            "Epoch:  18%|█▊        | 9/50 [19:44<1:29:44, 131.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 \t\t Training Loss: 335.5113084157308 \t\t Validation Loss: 681.6486282348633\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:48<00:00,  1.11it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:20<00:00,  1.49it/s]\n",
            "Epoch:  20%|██        | 10/50 [21:53<1:27:00, 130.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 \t\t Training Loss: 290.0534066518148 \t\t Validation Loss: 356.67499415079754\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:54<00:00,  1.04it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:19<00:00,  1.50it/s]\n",
            "Epoch:  22%|██▏       | 11/50 [24:08<1:25:42, 131.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 \t\t Training Loss: 97.33023811976115 \t\t Validation Loss: 103.2694595336914\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [02:08<00:00,  1.07s/it]\n",
            "Batch: 100%|██████████| 30/30 [00:20<00:00,  1.47it/s]\n",
            "Epoch:  24%|██▍       | 12/50 [26:37<1:26:53, 137.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 \t\t Training Loss: 73.61363122463226 \t\t Validation Loss: 116.61681950887045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [02:07<00:00,  1.06s/it]\n",
            "Batch: 100%|██████████| 30/30 [00:22<00:00,  1.36it/s]\n",
            "Epoch:  26%|██▌       | 13/50 [29:07<1:26:56, 140.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13 \t\t Training Loss: 67.01106807390849 \t\t Validation Loss: 105.63655331929525\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [02:00<00:00,  1.01s/it]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n",
            "Epoch:  28%|██▊       | 14/50 [31:26<1:24:19, 140.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 \t\t Training Loss: 63.48592314720154 \t\t Validation Loss: 91.3234790802002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.17it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.60it/s]\n",
            "Epoch:  30%|███       | 15/50 [33:28<1:18:35, 134.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15 \t\t Training Loss: 62.529546451568606 \t\t Validation Loss: 80.567338180542\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.17it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n",
            "Epoch:  32%|███▏      | 16/50 [35:29<1:14:05, 130.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16 \t\t Training Loss: 61.754215717315674 \t\t Validation Loss: 101.45159772237142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.18it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.62it/s]\n",
            "Epoch:  34%|███▍      | 17/50 [37:30<1:10:13, 127.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17 \t\t Training Loss: 58.80777832667033 \t\t Validation Loss: 89.8971108754476\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.17it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.60it/s]\n",
            "Epoch:  36%|███▌      | 18/50 [39:31<1:07:06, 125.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18 \t\t Training Loss: 57.620814339319864 \t\t Validation Loss: 86.15805435180664\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.18it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n",
            "Epoch:  38%|███▊      | 19/50 [41:32<1:04:13, 124.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19 \t\t Training Loss: 55.28716039657593 \t\t Validation Loss: 87.93601392110189\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.17it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.60it/s]\n",
            "Epoch:  40%|████      | 20/50 [43:34<1:01:45, 123.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20 \t\t Training Loss: 55.21012549400329 \t\t Validation Loss: 84.75843505859375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.17it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.58it/s]\n",
            "Epoch:  42%|████▏     | 21/50 [45:35<59:27, 123.00s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21 \t\t Training Loss: 54.881533257166545 \t\t Validation Loss: 107.65927543640137\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:43<00:00,  1.16it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.59it/s]\n",
            "Epoch:  44%|████▍     | 22/50 [47:37<57:16, 122.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22 \t\t Training Loss: 54.21261873245239 \t\t Validation Loss: 98.85206578572591\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.17it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.59it/s]\n",
            "Epoch:  46%|████▌     | 23/50 [49:39<55:01, 122.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23 \t\t Training Loss: 54.24686749776205 \t\t Validation Loss: 74.77725931803386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.17it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.60it/s]\n",
            "Epoch:  48%|████▊     | 24/50 [51:39<52:47, 121.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24 \t\t Training Loss: 53.72525807221731 \t\t Validation Loss: 87.6545841217041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.17it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n",
            "Epoch:  50%|█████     | 25/50 [53:41<50:42, 121.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25 \t\t Training Loss: 52.90116812388102 \t\t Validation Loss: 78.18968238830567\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.17it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.60it/s]\n",
            "Epoch:  52%|█████▏    | 26/50 [55:42<48:40, 121.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26 \t\t Training Loss: 51.99889353116353 \t\t Validation Loss: 63.61301383972168\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.17it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n",
            "Epoch:  54%|█████▍    | 27/50 [57:43<46:33, 121.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27 \t\t Training Loss: 52.04009663263957 \t\t Validation Loss: 93.7224355061849\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:43<00:00,  1.16it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.59it/s]\n",
            "Epoch:  56%|█████▌    | 28/50 [59:45<44:35, 121.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28 \t\t Training Loss: 53.14194663365682 \t\t Validation Loss: 102.72778689066568\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.17it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.60it/s]\n",
            "Epoch:  58%|█████▊    | 29/50 [1:01:47<42:32, 121.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29 \t\t Training Loss: 52.947429784139 \t\t Validation Loss: 65.91969108581543\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.17it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.63it/s]\n",
            "Epoch:  60%|██████    | 30/50 [1:03:48<40:26, 121.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30 \t\t Training Loss: 52.2106795946757 \t\t Validation Loss: 70.34419631958008\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:41<00:00,  1.18it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.60it/s]\n",
            "Epoch:  62%|██████▏   | 31/50 [1:05:48<38:21, 121.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31 \t\t Training Loss: 51.50639533996582 \t\t Validation Loss: 75.70920359293619\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.17it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.60it/s]\n",
            "Epoch:  64%|██████▍   | 32/50 [1:07:50<36:23, 121.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32 \t\t Training Loss: 51.85742920239766 \t\t Validation Loss: 91.45077298482259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:41<00:00,  1.18it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.63it/s]\n",
            "Epoch:  66%|██████▌   | 33/50 [1:09:50<34:16, 120.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33 \t\t Training Loss: 51.01295307477315 \t\t Validation Loss: 83.47077941894531\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.17it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n",
            "Epoch:  68%|██████▊   | 34/50 [1:11:51<32:15, 120.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34 \t\t Training Loss: 51.370682481924696 \t\t Validation Loss: 62.227705510457355\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.17it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n",
            "Epoch:  70%|███████   | 35/50 [1:13:52<30:13, 120.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35 \t\t Training Loss: 50.598077344894406 \t\t Validation Loss: 104.7566655476888\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.17it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n",
            "Epoch:  72%|███████▏  | 36/50 [1:15:53<28:13, 120.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36 \t\t Training Loss: 52.24769237836202 \t\t Validation Loss: 68.41997769673665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:43<00:00,  1.16it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.59it/s]\n",
            "Epoch:  74%|███████▍  | 37/50 [1:17:55<26:16, 121.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37 \t\t Training Loss: 51.97657525539398 \t\t Validation Loss: 88.87285957336425\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.17it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.63it/s]\n",
            "Epoch:  76%|███████▌  | 38/50 [1:19:56<24:12, 121.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38 \t\t Training Loss: 51.03366045951843 \t\t Validation Loss: 74.30214513142904\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.17it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.59it/s]\n",
            "Epoch:  78%|███████▊  | 39/50 [1:21:57<22:12, 121.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39 \t\t Training Loss: 52.78655196825663 \t\t Validation Loss: 76.6105520884196\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.17it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.63it/s]\n",
            "Epoch:  80%|████████  | 40/50 [1:23:58<20:11, 121.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40 \t\t Training Loss: 51.61776730219523 \t\t Validation Loss: 80.90800908406575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.17it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.60it/s]\n",
            "Epoch:  82%|████████▏ | 41/50 [1:25:59<18:11, 121.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41 \t\t Training Loss: 50.778597036997475 \t\t Validation Loss: 77.73362210591634\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.17it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n",
            "Epoch:  84%|████████▍ | 42/50 [1:28:01<16:10, 121.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42 \t\t Training Loss: 50.43333905537923 \t\t Validation Loss: 74.38857714335124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.17it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.60it/s]\n",
            "Epoch:  86%|████████▌ | 43/50 [1:30:02<14:09, 121.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43 \t\t Training Loss: 49.995711874961856 \t\t Validation Loss: 69.68075014750163\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:41<00:00,  1.18it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n",
            "Epoch:  88%|████████▊ | 44/50 [1:32:03<12:06, 121.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44 \t\t Training Loss: 49.55943454106649 \t\t Validation Loss: 70.38444073994954\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.18it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n",
            "Epoch:  90%|█████████ | 45/50 [1:34:04<10:05, 121.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45 \t\t Training Loss: 49.713704363505045 \t\t Validation Loss: 75.16250979105631\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.17it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.62it/s]\n",
            "Epoch:  92%|█████████▏| 46/50 [1:36:05<08:04, 121.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46 \t\t Training Loss: 50.06358323097229 \t\t Validation Loss: 65.58581504821777\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:41<00:00,  1.18it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.62it/s]\n",
            "Epoch:  94%|█████████▍| 47/50 [1:38:05<06:02, 120.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47 \t\t Training Loss: 49.46700139840444 \t\t Validation Loss: 74.979984664917\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:41<00:00,  1.18it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n",
            "Epoch:  96%|█████████▌| 48/50 [1:40:06<04:01, 120.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48 \t\t Training Loss: 48.35977013111115 \t\t Validation Loss: 91.11478169759114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:41<00:00,  1.18it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.60it/s]\n",
            "Epoch:  98%|█████████▊| 49/50 [1:42:06<02:00, 120.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49 \t\t Training Loss: 50.96495172182719 \t\t Validation Loss: 69.28762830098471\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 120/120 [01:42<00:00,  1.17it/s]\n",
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.61it/s]\n",
            "Epoch: 100%|██████████| 50/50 [1:44:08<00:00, 124.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50 \t\t Training Loss: 49.25429754257202 \t\t Validation Loss: 64.07692985534668\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "min_valid_loss = np.inf\n",
        "\n",
        "for epoch in tqdm(range(1, num_epochs + 1), desc = 'Epoch', position = 0):\n",
        "    train_loss, n = 0.0, 0\n",
        "    model.train()\n",
        "    \n",
        "    for x, y in tqdm(train_iter, desc = 'Batch', position = 0):\n",
        "        # get model predictions and compute loss\n",
        "        y_pred = model(x.to(device), edge_index, edge_weight)\n",
        "        loss = torch.mean((y_pred-y)**2)\n",
        "        # backpropogation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    valid_loss = 0.0\n",
        "    model.eval() \n",
        "    for x, y in tqdm(val_iter, desc = 'Batch', position = 0):\n",
        "        # get model predictions and compute loss\n",
        "        y_pred = model(x.to(device), edge_index, edge_weight)\n",
        "        loss = torch.mean((y_pred-y)**2)\n",
        "        valid_loss += loss.item() \n",
        "\n",
        "    print(f'Epoch {epoch} \\t\\t Training Loss: {train_loss/120} \\t\\t Validation Loss: {valid_loss/30}')\n",
        "    if min_valid_loss > valid_loss:\n",
        "        min_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), model_save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0baa8a43-e106-4c9c-88ef-bb5e400107f4",
      "metadata": {
        "id": "0baa8a43-e106-4c9c-88ef-bb5e400107f4"
      },
      "source": [
        "Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d761fee-d8fa-411f-94fb-9aec70b9fe1c",
      "metadata": {
        "id": "7d761fee-d8fa-411f-94fb-9aec70b9fe1c",
        "outputId": "6c457037-23d4-4ea9-8e2c-675148c9e3a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batch: 100%|██████████| 30/30 [00:18<00:00,  1.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([60, 288, 98, 1])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# load model with lowest validation lost\n",
        "best_model = STConvAE(device, num_nodes, channels, num_layers, kernel_size, K, n_his, kernel_size_de, stride, padding, normalization = 'sym', bias = True).to(device)\n",
        "best_model.load_state_dict(torch.load(model_save_path))\n",
        "\n",
        "best_model.eval()\n",
        "cost = 0\n",
        "missing_count = 0\n",
        "predicted = []\n",
        "ground_truth = []\n",
        "\n",
        "i = 1\n",
        "\n",
        "for x, y in tqdm(test_iter, desc = 'Batch', position = 0):\n",
        "    # get model predictions and compute loss\n",
        "    y_pred = best_model(x.to(device), edge_index, edge_weight)\n",
        "    if i == 1:\n",
        "        y_pred_complete = y_pred\n",
        "    else:\n",
        "        y_pred_complete = torch.cat((y_pred_complete, y_pred), 0)\n",
        "    i+=1\n",
        "\n",
        "print(y_pred_complete.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5827ad6-588f-4040-9b66-dee81b2af070",
      "metadata": {
        "id": "f5827ad6-588f-4040-9b66-dee81b2af070"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "dtr = pd.date_range(start='2016-06-27', end='2016-08-26', freq='5min')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "310afdeb-4d23-4769-b8b6-a565afea33f6",
      "metadata": {
        "id": "310afdeb-4d23-4769-b8b6-a565afea33f6",
        "outputId": "1304b9c8-df07-4996-e181-515dafd7ca08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test RMSE of STGCN-DAE is: 11.5665137670197\n",
            "Test MAE is of STGCN-DAE is: tensor(5.9378, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "from math import sqrt\n",
        "pred = y_pred_complete[x_test.cpu().numpy()==-1]\n",
        "ground_truth = y_test[x_test.cpu().numpy()==-1]\n",
        "print(\"Test RMSE of STGCN-DAE is: \"+ str(sqrt(torch.mean((pred-ground_truth)**2))))\n",
        "print(\"Test MAE is of STGCN-DAE is: \"+ str(torch.mean(abs(pred-ground_truth))))\n",
        "y_pred_complete = torch.squeeze(y_pred_complete)\n",
        "y_pred_complete = y_pred_complete.reshape(17280,98)\n",
        "y_pred_complete = pd.DataFrame(y_pred_complete.cpu().detach().numpy())\n",
        "y_pred_complete['tmst']=dtr[0:17280]\n",
        "y_pred_complete.to_csv('./Model_results/12hrBM_STGCN_DAE_Imputed.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Baseline\n",
        "Only four baselines are here. Scripts for baselines MIDA and LRTC-TNN are ran separately."
      ],
      "metadata": {
        "id": "CmahC9sDtdNe"
      },
      "id": "CmahC9sDtdNe"
    },
    {
      "cell_type": "markdown",
      "id": "17dd893f-92f5-4a9b-b62f-55755a380ce9",
      "metadata": {
        "id": "17dd893f-92f5-4a9b-b62f-55755a380ce9"
      },
      "source": [
        "LI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bc10eca-9064-4d49-b47e-1079e4299c7a",
      "metadata": {
        "id": "5bc10eca-9064-4d49-b47e-1079e4299c7a",
        "outputId": "2915a00f-f9a0-4e8a-cdfa-bf458f9f4841"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test RMSE of Linear Interpolation is: 27.505340612452542\n",
            "Test MAE of Linear Interpolation is: tensor(20.2995)\n"
          ]
        }
      ],
      "source": [
        "#Linear Interpolation\n",
        "corrupted_test_x[corrupted_test_x==-1] = np.nan\n",
        "test = pd.DataFrame(corrupted_test_x.numpy())\n",
        "LI_imputed = test.interpolate(method ='linear', limit_direction ='forward')\n",
        "#LI_imputed = LI_imputed.dropna()\n",
        "LI_imputed = LI_imputed.fillna(LI_imputed.mean())\n",
        "LI_imputed = torch.tensor(LI_imputed.values)\n",
        "LI_pred = LI_imputed[~mask[86400:103680,]]\n",
        "print(\"Test RMSE of Linear Interpolation is: \"+ str(sqrt(torch.mean((LI_pred.cpu()-ground_truth.cpu())**2))))\n",
        "print(\"Test MAE of Linear Interpolation is: \"+ str(torch.mean(abs(LI_pred.cpu()-ground_truth.cpu()))))\n",
        "\n",
        "y_pred_complete = pd.DataFrame(LI_imputed.cpu().detach().numpy())\n",
        "y_pred_complete['tmst']=dtr[0:17280]\n",
        "y_pred_complete.to_csv('./Model_results/12hrBM_LI_Imputed.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "083147e5-7788-489f-ba58-67b04b72486f",
      "metadata": {
        "id": "083147e5-7788-489f-ba58-67b04b72486f"
      },
      "source": [
        "Mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c357bb3-7a03-4a90-9382-2f3f8a649c4c",
      "metadata": {
        "id": "7c357bb3-7a03-4a90-9382-2f3f8a649c4c",
        "outputId": "b8cf4d31-536e-4d83-a54d-141773a00e9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test RMSE of Mean Imputation is: 37.367874333798575\n",
            "Test MAE of Mean Imputation is: tensor(28.7702)\n"
          ]
        }
      ],
      "source": [
        "#Mean Imputation\n",
        "from math import sqrt\n",
        "corrupted_test_x[corrupted_test_x==-1] = np.nan\n",
        "test = pd.DataFrame(corrupted_test_x.numpy())\n",
        "Mean_imputed = test.fillna(test.mean())\n",
        "Mean_imputed = torch.tensor(Mean_imputed.values)\n",
        "Mean_pred = Mean_imputed[~mask[86400:103680,]]\n",
        "print(\"Test RMSE of Mean Imputation is: \"+ str(sqrt(torch.mean((Mean_pred.cpu()-ground_truth.cpu())**2))))\n",
        "print(\"Test MAE of Mean Imputation is: \"+ str(torch.mean(abs(Mean_pred.cpu()-ground_truth.cpu()))))\n",
        "\n",
        "y_pred_complete = pd.DataFrame(Mean_imputed.cpu().detach().numpy())\n",
        "y_pred_complete['tmst']=dtr[0:17280]\n",
        "y_pred_complete.to_csv('./Model_results/12hrBM_Mean_Imputed.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02f71abe-28e0-42c5-97b7-b35f8c18a24d",
      "metadata": {
        "id": "02f71abe-28e0-42c5-97b7-b35f8c18a24d"
      },
      "source": [
        "MICE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "529e8c69-e869-4bc2-bb5f-716477b1a692",
      "metadata": {
        "id": "529e8c69-e869-4bc2-bb5f-716477b1a692",
        "outputId": "e92daea1-0765-44ac-a3e8-84345a4a2a4b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/rxf131/ondemand/ubuntu2004/torch-geometric-temporal/sklearn/impute/_iterative.py:699: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test RMSE of MICE Interpolation is: 26.79346393194908\n",
            "Test MAE of MICE Interpolation is: tensor(17.6322)\n"
          ]
        }
      ],
      "source": [
        "#MICE\n",
        "import numpy as np\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "knn = KNeighborsRegressor()\n",
        "imp = IterativeImputer(estimator = knn, max_iter = 1, initial_strategy = 'median', imputation_order='ascending',random_state=42)\n",
        "corrupted_train_x[corrupted_train_x==-1] = np.nan\n",
        "train = pd.DataFrame(corrupted_train_x.numpy())\n",
        "imp.fit(train)\n",
        "corrupted_test_x[corrupted_test_x==-1] = np.nan\n",
        "test = pd.DataFrame(corrupted_test_x.numpy())\n",
        "MICE_imputed = imp.transform(test)\n",
        "MICE_imputed = pd.DataFrame(MICE_imputed)\n",
        "MICE_imputed = torch.tensor(MICE_imputed.values)\n",
        "MICE_pred = MICE_imputed[~mask[86400:103680,]]\n",
        "ground_truth = y_test[x_test.cpu().numpy()==-1]\n",
        "print(\"Test RMSE of MICE Interpolation is: \"+ str(sqrt(torch.mean((MICE_pred.cpu()-ground_truth.cpu())**2))))\n",
        "print(\"Test MAE of MICE Interpolation is: \"+ str(torch.mean(abs(MICE_pred.cpu()-ground_truth.cpu()))))\n",
        "\n",
        "y_pred_complete = pd.DataFrame(MICE_imputed.cpu().detach().numpy())\n",
        "y_pred_complete['tmst']=dtr[0:17280]\n",
        "y_pred_complete.to_csv('./Model_results/12hrBM_MICE_Imputed.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37e61f31-3c13-4e93-8d81-e78b1519977e",
      "metadata": {
        "id": "37e61f31-3c13-4e93-8d81-e78b1519977e"
      },
      "source": [
        "KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a3cb3a0-30f3-4149-a1ef-c0ea886e4a5e",
      "metadata": {
        "id": "7a3cb3a0-30f3-4149-a1ef-c0ea886e4a5e",
        "outputId": "e7965947-64dc-4c8c-86ba-3662737b50aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test RMSE of KNN Interpolation is: 21.324861672278132\n",
            "Test MAE of KNN Interpolation is: tensor(13.0600)\n"
          ]
        }
      ],
      "source": [
        "# KNN Imputation\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "corrupted_train_x[corrupted_train_x==-1] = np.nan\n",
        "train = pd.DataFrame(corrupted_train_x.numpy())\n",
        "imputer.fit(train)\n",
        "KNN_imputed = imputer.transform(test)\n",
        "KNN_imputed = pd.DataFrame(KNN_imputed)\n",
        "KNN_imputed = torch.tensor(KNN_imputed.values)\n",
        "KNN_pred = KNN_imputed[~mask[86400:103680,]]\n",
        "print(\"Test RMSE of KNN Interpolation is: \"+ str(sqrt(torch.mean((KNN_pred.cpu()-ground_truth.cpu())**2))))\n",
        "print(\"Test MAE of KNN Interpolation is: \"+ str(torch.mean(abs(KNN_pred.cpu()-ground_truth.cpu()))))\n",
        "\n",
        "y_pred_complete = pd.DataFrame(KNN_imputed.cpu().detach().numpy())\n",
        "y_pred_complete['tmst']=dtr[0:17280]\n",
        "y_pred_complete.to_csv('./Model_results/12hrBM_KNN_Imputed.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c42709d-c2f2-438d-b97b-8ef3a27b9977",
      "metadata": {
        "id": "0c42709d-c2f2-438d-b97b-8ef3a27b9977"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "STD-GAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}